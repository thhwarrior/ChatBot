{"cells":[{"cell_type":"code","source":["a = []\n","while(1):\n","    a.append('1')"],"metadata":{"id":"cF4i_aGYfemR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6255,"status":"ok","timestamp":1695224532206,"user":{"displayName":"Syed Hamza Ali Shah","userId":"17869590705840704655"},"user_tz":-300},"id":"YutCmSqPziIb","outputId":"13f00359-651c-4429-cbb6-4bb648ff871d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.5.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.23.0)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.41.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.3.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.0.1+cu118)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft) (16.0.6)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"]}],"source":["  !pip install transformers datasets peft accelerate bitsandbytes safetensors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obqz6dBo8kdC"},"outputs":[],"source":["import os, sys\n","import torch\n","import datasets\n","from transformers import (\n","    pipeline,\n","    AutoTokenizer,\n","    AutoModelForCausalLM,\n","    BitsAndBytesConfig,\n","    DataCollatorForLanguageModeling,\n","    DataCollatorForSeq2Seq,\n","    Trainer,\n","    TrainingArguments,\n","    GenerationConfig\n",")\n","from peft import PeftModel, LoraConfig, prepare_model_for_kbit_training, get_peft_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-yI83TYB9t20"},"outputs":[],"source":["### config ###\n","model_id = \"togethercomputer/LLaMA-2-7B-32K\"\n","max_length = 512\n","device_map = \"auto\"\n","batch_size = 128\n","micro_batch_size = 32\n","gradient_accumulation_steps = batch_size // micro_batch_size\n","\n","# nf4\" use a symmetric quantization scheme with 4 bits precision\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["d0e8710ebc3f48d2bc1b9c0eb2bec5aa","5b5f2c20b2b54821aa3b28e594a48eba","fca4762a512244bbbbc0b44fbe57161a","771b00849e82463189733cf4c55f654c","7649bd0dc5534960bdbab77830c2d88b","62271b38b6134d01adfe2b412963758f","be38e498489c4f3cb75baa040976a9b8","12b368cb2b5847fa82be8512eb4e57a8","b63d9e2e6de94faaa3cc6e43f79c6661","27b2323ae4fe4d52a32477a81814a609","433606f043724dfbb59043f390c61b77"]},"id":"JeJHAutBpBEz","outputId":"dc398a28-234c-4e98-9d98-6372894964ec"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0e8710ebc3f48d2bc1b9c0eb2bec5aa"}},"metadata":{}}],"source":["# load model from huggingface\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    quantization_config=bnb_config,\n","    use_cache=False,\n","    device_map=device_map,\n","    token = \"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\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"miaolLg2BMLa"},"outputs":[],"source":["# load tokenizer from huggingface\n","tokenizer = AutoTokenizer.from_pretrained(model_id, token = \"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\")\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TgkwujUwAfiC"},"outputs":[],"source":["### generate ###\n","prompt = \"\"\"<s>[INST] <<SYS>>\n","Write a response that appropriately completes the request.\n","<</SYS>>\n","\n","What are some unique sports?[/INST]\"\"\"\n","inputs = tokenizer(prompt, return_tensors=\"pt\")\n","generate_ids = model.generate(\n","    inputs.input_ids,\n","    do_sample=True,\n","    top_k=10,\n","    top_p=0.7,\n","    num_return_sequences=1,\n","    eos_token_id=tokenizer.eos_token_id,\n","    max_length=300,\n","    repetition_penalty=1.1,\n","    )\n","res = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n","print(res)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4ocQxucnUeu"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWujIJ28oflD"},"outputs":[],"source":["### generate prompt based on template ###\n","prompt_template = {\n","    \"prompt\": \\\n","    \"Below is an instruction that describes a task.\\\n","    {context}\\\n","    \\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n\",\n","\n","    \"response_split\": \"### Response:\"\n","}\n","\n","def generate_prompt(instruction, label=None, context=\"Write a response that appropriately completes the request.\", prompt_template=prompt_template):\n","\n","    res = prompt_template[\"prompt\"].format(\n","        instruction=instruction,context=context)\n","    if label:\n","        res = f\"{res}{label}\"\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fn7uyrKgCrpQ"},"outputs":[],"source":["Tmax_length = 256\n","dataset = (datasets.load_dataset(\"pandas\", data_files = \"/content/drive/MyDrive/data.pkl\", split='train').train_test_split(train_size=0.9, test_size=0.1))\n","dataset['test'][2]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pB8sNhy0Dszd"},"outputs":[],"source":["def tokenize(tokenizer, prompt, max_length=max_length, add_eos_token=False):\n","    result = tokenizer(\n","        prompt,\n","        truncation=True,\n","        max_length=max_length,\n","        padding=False,\n","        return_tensors=None)\n","\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result\n","\n","def generate_and_tokenize_prompt(data_point):\n","    full_prompt = generate_prompt(\n","        data_point[\"instruction\"],\n","        data_point[\"response\"],\n","    )\n","    tokenized_full_prompt = tokenize(tokenizer, full_prompt)\n","    user_prompt = generate_prompt(data_point[\"instruction\"])\n","    tokenized_user_prompt = tokenize(tokenizer, user_prompt)\n","    user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n","    mask_token = [-100] * user_prompt_len\n","    tokenized_full_prompt[\"labels\"] = mask_token + tokenized_full_prompt[\"labels\"][user_prompt_len:]\n","    return tokenized_full_prompt\n","\n","cols = [\"instruction\",\"response\"]\n","train_data = dataset[\"train\"].shuffle().map(generate_and_tokenize_prompt, remove_columns=cols)\n","val_data = dataset[\"test\"].shuffle().map(generate_and_tokenize_prompt, remove_columns=cols,)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Nu97i5Jy91t"},"outputs":[],"source":["train_data[1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Ti5XnKS-Pry"},"outputs":[],"source":["def print_number_of_trainable_model_parameters(model):\n","    trainable_model_params = 0\n","    all_model_params = 0\n","    for _, param in model.named_parameters():\n","        all_model_params += param.numel()\n","        if param.requires_grad:\n","            trainable_model_params += param.numel()\n","    print(f\"trainable model parameters: {trainable_model_params}. All model parameters: {all_model_params} \")\n","    return trainable_model_params\n","\n","ori_p = print_number_of_trainable_model_parameters(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47j2yQjnApEq"},"outputs":[],"source":["# LoRA config\n","model = prepare_model_for_kbit_training(model)\n","peft_config = LoraConfig(\n","    r=8,\n","    lora_alpha=32,\n","    lora_dropout=0.1,\n","    target_modules=[\"q_proj\", \"v_proj\"],\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n",")\n","model = get_peft_model(model, peft_config)\n","\n","### compare trainable parameters #\n","peft_p = print_number_of_trainable_model_parameters(model)\n","print(f\"# Trainable Parameter \\nBefore: {ori_p} \\nAfter: {peft_p} \\nPercentage: {round(peft_p / ori_p * 100, 2)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3HQxIWYZFBoH"},"outputs":[],"source":["args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/ChatModel\",\n","    num_train_epochs=20,\n","    max_steps=200,\n","    fp16=True,\n","    optim=\"paged_adamw_32bit\",\n","    learning_rate=2e-4,\n","    lr_scheduler_type=\"constant\",\n","    per_device_train_batch_size=micro_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    gradient_checkpointing=True,\n","    group_by_length=False,\n","    logging_steps=10,\n","    save_strategy=\"epoch\",\n","    save_total_limit=3,\n","    disable_tqdm=False,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    train_dataset=train_data,\n","    eval_dataset=val_data,\n","    args=args,\n","    data_collator=DataCollatorForSeq2Seq(\n","      tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True),\n",")\n","\n","# silence the warnings. re-enable for inference!\n","model.config.use_cache = False\n","trainer.train()\n","model.save_pretrained(\"/content/drive/MyDrive/ChatModel\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JMz0r2a8668R"},"outputs":[],"source":["# nf4\" use a symmetric quantization scheme with 4 bits precision\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8SNLBKgI4Mg"},"outputs":[],"source":["# model path and weight\n","model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n","peft_path = \"thhwarrior/Llama2-Tukl\"\n","\n","# loading model\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    quantization_config=bnb_config,\n","    use_cache=True,\n","    device_map=\"auto\",\n","    token = \"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\"\n",")\n","\n","# loading peft weight\n","model = PeftModel.from_pretrained(\n","    model,\n","    peft_path,\n","    torch_dtype=torch.float16,\n",")\n","model.eval()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgg6wYWDV84q"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jod6Hcq_Qn71"},"outputs":[],"source":["# generation config\n","generation_config = GenerationConfig(\n","    do_sample=False,\n","    temperature=0.1,\n","    top_p=0.75,\n","    top_k=1,\n","    num_beams=4, # beam search\n",")\n","# generating reply\n","with torch.no_grad():\n","    prompt = \"best countries for tourists?\"\n","    inputs = tokenizer(prompt, return_tensors=\"pt\")\n","    generation_output = model.generate(\n","        input_ids=inputs.input_ids.to('cuda'),\n","        generation_config=generation_config,\n","        return_dict_in_generate=True,\n","        output_scores=True,\n","        max_new_tokens=64,\n","    )\n","    print('\\nAnswer: ', tokenizer.decode(generation_output.sequences[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Or0LP1E7ODSB"},"outputs":[],"source":["pipeline = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n",")\n","\n","sequences = pipeline(\n","    'I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of other shows I might like?\\n',\n","    do_sample=True,\n","    top_k=10,\n","    num_return_sequences=1,\n","    eos_token_id=tokenizer.eos_token_id,\n","    max_length=200,\n",")\n","for seq in sequences:\n","    print(f\"Result: {seq['generated_text']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jma5AQ1BE9Cq"},"outputs":[],"source":["model.save_pretrained(\"/content/drive/MyDrive/Llama2-Tukl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pl0gYsd0SPJQ"},"outputs":[],"source":["model.push_to_hub(\"Llama2-Tukl\", token = \"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\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RIOy49tqukgf"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d0e8710ebc3f48d2bc1b9c0eb2bec5aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b5f2c20b2b54821aa3b28e594a48eba","IPY_MODEL_fca4762a512244bbbbc0b44fbe57161a","IPY_MODEL_771b00849e82463189733cf4c55f654c"],"layout":"IPY_MODEL_7649bd0dc5534960bdbab77830c2d88b"}},"5b5f2c20b2b54821aa3b28e594a48eba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62271b38b6134d01adfe2b412963758f","placeholder":"​","style":"IPY_MODEL_be38e498489c4f3cb75baa040976a9b8","value":"Loading checkpoint shards:   0%"}},"fca4762a512244bbbbc0b44fbe57161a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_12b368cb2b5847fa82be8512eb4e57a8","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b63d9e2e6de94faaa3cc6e43f79c6661","value":0}},"771b00849e82463189733cf4c55f654c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27b2323ae4fe4d52a32477a81814a609","placeholder":"​","style":"IPY_MODEL_433606f043724dfbb59043f390c61b77","value":" 0/2 [00:00&lt;?, ?it/s]"}},"7649bd0dc5534960bdbab77830c2d88b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62271b38b6134d01adfe2b412963758f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be38e498489c4f3cb75baa040976a9b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12b368cb2b5847fa82be8512eb4e57a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b63d9e2e6de94faaa3cc6e43f79c6661":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27b2323ae4fe4d52a32477a81814a609":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"433606f043724dfbb59043f390c61b77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}